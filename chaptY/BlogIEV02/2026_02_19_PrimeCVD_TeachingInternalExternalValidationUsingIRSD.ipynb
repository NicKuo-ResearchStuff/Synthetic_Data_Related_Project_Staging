{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpeLSSCj7r-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "503252b8-81ff-474b-dcbc-78bd794e3c57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lifelines\n",
            "  Downloading lifelines-0.30.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from lifelines) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from lifelines) (1.16.3)\n",
            "Requirement already satisfied: pandas<3.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from lifelines) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.12/dist-packages (from lifelines) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.12/dist-packages (from lifelines) (1.8.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines)\n",
            "  Downloading formulaic-1.2.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: narwhals>=1.17 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines) (2.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines) (2.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=2.1->lifelines) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=2.1->lifelines) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n",
            "Downloading lifelines-0.30.1-py3-none-any.whl (350 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.0/350.0 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.2.1-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.3/117.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=154a7da9b41900dfe0be0bfd209c43bc4b809c844c8526c852c4b484f7ef0cb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/37/21/0a719b9d89c635e89ff24bd93b862882ad675279552013b2fb\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, autograd-gamma, formulaic, lifelines\n",
            "Successfully installed autograd-gamma-0.5.0 formulaic-1.2.1 interface-meta-1.3.0 lifelines-0.30.1\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------------\n",
        "# 0) Install libraries\n",
        "# ------------------------------------------------------------\n",
        "!pip install lifelines\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Imports\n",
        "# ------------------------------------------------------------\n",
        "import os, random, copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Reproducibility\n",
        "# ------------------------------------------------------------\n",
        "RNG_SEED = 42\n",
        "def seed_all(seed=RNG_SEED):\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "seed_all(RNG_SEED)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) Load data\n",
        "# ------------------------------------------------------------\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Paper(2025Dec)_SimulatedCVD/Data001_ReadyForCoxPH.csv\")\n",
        "for col in [\"Unnamed: 0\", \"index\"]:\n",
        "    if col in df.columns:\n",
        "        df = df.drop(columns=[col])\n",
        "df_raw = copy.copy(df)\n",
        "\n",
        "# Basic sanity checks (optional)\n",
        "required_cols = [\"cvd_time\", \"cvd_event\", \"IRSD_quintile\", \"Age\", \"smoking_status\",\n",
        "                 \"AF\", \"CKD\", \"diabetes\", \"HbA1c\", \"eGFR\", \"SBP\"]\n",
        "missing = [c for c in required_cols if c not in df_raw.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing required columns: {missing}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 4) Transform once: age centering\n",
        "# ------------------------------------------------------------\n",
        "df_raw = df_raw.copy()\n",
        "df_raw[\"Age_c\"] = df_raw[\"Age\"] - 30.0\n",
        "\n",
        "# Ensure types\n",
        "for col in [\"AF\", \"CKD\", \"diabetes\", \"cvd_event\"]:\n",
        "    df_raw[col] = df_raw[col].astype(int)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5) Feature builder WITHOUT IRSD as a feature\n",
        "# ------------------------------------------------------------\n",
        "def build_X_no_irsd(df, drop_cols=None):\n",
        "    df = df.copy()\n",
        "\n",
        "    # smoking dummies (baseline = non-smoker)\n",
        "    smoke = pd.get_dummies(df[\"smoking_status\"], prefix=\"smoke\").fillna(0)\n",
        "    if \"smoke_non\" in smoke.columns:\n",
        "        smoke = smoke.drop(columns=[\"smoke_non\"])\n",
        "\n",
        "    X = pd.concat(\n",
        "        [\n",
        "            df[[\"Age_c\", \"AF\", \"CKD\", \"diabetes\", \"HbA1c\", \"eGFR\", \"SBP\"]],\n",
        "            smoke,\n",
        "        ],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # drop near-constant cols based on (training) df only\n",
        "    if drop_cols is None:\n",
        "        events = df[\"cvd_event\"].astype(bool)\n",
        "        drop_cols = []\n",
        "        for c in X.columns:\n",
        "            v_all = X[c].var()\n",
        "            v_e   = X.loc[events, c].var() if events.any() else 0.0\n",
        "            v_ne  = X.loc[~events, c].var() if (~events).any() else 0.0\n",
        "            if (v_all < 1e-6) or (v_e < 1e-6) or (v_ne < 1e-6):\n",
        "                drop_cols.append(c)\n",
        "\n",
        "    return X.drop(columns=drop_cols, errors=\"ignore\"), drop_cols\n",
        "\n"
      ],
      "metadata": {
        "id": "wr1xqybi-jlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 6) Calibration helpers (censoring-aware observed risk via KM within bins)\n",
        "# ------------------------------------------------------------\n",
        "def predict_risk_at_t(cph, X, t):\n",
        "    S_t = cph.predict_survival_function(X, times=[t]).iloc[0].to_numpy(float)\n",
        "    return np.clip(1.0 - S_t, 0.0, 1.0)\n",
        "\n",
        "def km_event_risk_at_t(times, events, t):\n",
        "    \"\"\"\n",
        "    Estimate P(T <= t) = 1 - S_KM(t) in a group.\n",
        "    Returns NaN if not enough data.\n",
        "    \"\"\"\n",
        "    times = np.asarray(times, dtype=float)\n",
        "    events = np.asarray(events, dtype=int)\n",
        "\n",
        "    if len(times) < 10:\n",
        "        return np.nan\n",
        "\n",
        "    kmf = KaplanMeierFitter()\n",
        "    try:\n",
        "        kmf.fit(durations=times, event_observed=events)\n",
        "        s_t = float(kmf.survival_function_at_times(t).iloc[0])\n",
        "        return float(np.clip(1.0 - s_t, 0.0, 1.0))\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "def calibration_d21_by_qbins(risk_t, y_time, y_event, t, K=20):\n",
        "    \"\"\"\n",
        "    Bin by predicted risk quantiles, then compute:\n",
        "      r_bar: mean predicted risk per bin\n",
        "      y_bar: KM-estimated observed event risk by t per bin\n",
        "    Fit y_bar ≈ a * r_bar (through origin), return D21 = |1 - a|\n",
        "    \"\"\"\n",
        "    tmp = pd.DataFrame({\n",
        "        \"risk\":  np.asarray(risk_t, dtype=float),\n",
        "        \"time\":  np.asarray(y_time, dtype=float),\n",
        "        \"event\": np.asarray(y_event, dtype=int),\n",
        "    }).dropna()\n",
        "\n",
        "    if tmp.shape[0] < 50:\n",
        "        return np.nan, np.nan, np.array([]), np.array([])\n",
        "\n",
        "    tmp = tmp.sort_values(\"risk\").reset_index(drop=True)\n",
        "    tmp[\"bin\"] = pd.qcut(tmp[\"risk\"], q=K, duplicates=\"drop\")\n",
        "\n",
        "    r_bar, y_bar = [], []\n",
        "    for _, g in tmp.groupby(\"bin\", observed=False):\n",
        "        r_mean = float(g[\"risk\"].mean())\n",
        "        y_km = km_event_risk_at_t(g[\"time\"].to_numpy(float), g[\"event\"].to_numpy(int), t)\n",
        "        if np.isfinite(r_mean) and np.isfinite(y_km):\n",
        "            r_bar.append(r_mean)\n",
        "            y_bar.append(y_km)\n",
        "\n",
        "    r_bar = np.asarray(r_bar, dtype=float)\n",
        "    y_bar = np.asarray(y_bar, dtype=float)\n",
        "\n",
        "    if len(r_bar) < 3 or float(np.dot(r_bar, r_bar)) == 0.0:\n",
        "        return np.nan, np.nan, r_bar, y_bar\n",
        "\n",
        "    a = float(np.dot(r_bar, y_bar) / np.dot(r_bar, r_bar))\n",
        "    d21 = float(abs(1.0 - a))\n",
        "    return a, d21, r_bar, y_bar\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 7) Settings for calibration\n",
        "# ------------------------------------------------------------\n",
        "t = 4.88\n",
        "K = 20\n",
        "penalizer = 0.05"
      ],
      "metadata": {
        "id": "hvpUA75e-pUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 8) BASELINE comparator:\n",
        "#    Train on ALL IRSD (but WITHOUT IRSD as a feature)\n",
        "#    Then evaluate calibration (D21) separately within each IRSD quintile.\n",
        "# ------------------------------------------------------------\n",
        "X_all, drop_cols_all = build_X_no_irsd(df_raw, drop_cols=None)\n",
        "surv_all = pd.concat(\n",
        "    [df_raw[[\"cvd_time\", \"cvd_event\", \"IRSD_quintile\"]].reset_index(drop=True),\n",
        "     X_all.reset_index(drop=True)],\n",
        "    axis=1\n",
        ").dropna()\n",
        "\n",
        "cph_baseline = CoxPHFitter(penalizer=penalizer)\n",
        "cph_baseline.fit(surv_all.drop(columns=[\"IRSD_quintile\"]), duration_col=\"cvd_time\", event_col=\"cvd_event\")\n",
        "\n",
        "baseline_rows = []\n",
        "for q in sorted(surv_all[\"IRSD_quintile\"].dropna().unique()):\n",
        "    q = int(q)\n",
        "    g = surv_all[surv_all[\"IRSD_quintile\"] == q].copy()\n",
        "    if g.shape[0] < 200:\n",
        "        baseline_rows.append((q, np.nan, np.nan, g.shape[0]))\n",
        "        continue\n",
        "\n",
        "    y_time = g[\"cvd_time\"].to_numpy(float)\n",
        "    y_event = g[\"cvd_event\"].to_numpy(int)\n",
        "    Xg = g.drop(columns=[\"cvd_time\", \"cvd_event\", \"IRSD_quintile\"])\n",
        "\n",
        "    risk_t = predict_risk_at_t(cph_baseline, Xg, t)\n",
        "    a, d21, _, _ = calibration_d21_by_qbins(risk_t, y_time, y_event, t, K=K)\n",
        "    baseline_rows.append((q, a, d21, g.shape[0]))\n",
        "\n",
        "baseline_df = pd.DataFrame(baseline_rows, columns=[\"IRSD_quintile\", \"a_baseline\", \"D21_baseline\", \"n_test\"])\n",
        "print(\"\\n=== Baseline: train on ALL IRSD (no IRSD feature), evaluate within each IRSD ===\")\n",
        "print(baseline_df.sort_values(\"IRSD_quintile\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d75EaCWs-sD-",
        "outputId": "9caaa1cb-8fc8-4e05-cdb4-40b751f8064d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Baseline: train on ALL IRSD (no IRSD feature), evaluate within each IRSD ===\n",
            "   IRSD_quintile  a_baseline  D21_baseline  n_test\n",
            "0              1    1.167178      0.167178   10640\n",
            "1              2    1.254565      0.254565    8055\n",
            "2              3    1.221137      0.221137   11941\n",
            "3              4    1.166861      0.166861    8495\n",
            "4              5    1.111325      0.111325   10869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# 9) INTERNAL–EXTERNAL (leave-one-IRSD-out):\n",
        "#    For each q:\n",
        "#      Train on IRSD != q (no IRSD feature)\n",
        "#      Test on IRSD == q\n",
        "#      Compute D21 on that held-out stratum\n",
        "# ------------------------------------------------------------\n",
        "loo_rows = []\n",
        "\n",
        "for q in sorted(df_raw[\"IRSD_quintile\"].dropna().unique()):\n",
        "    q = int(q)\n",
        "\n",
        "    train_q = df_raw[df_raw[\"IRSD_quintile\"] != q].copy()\n",
        "    test_q  = df_raw[df_raw[\"IRSD_quintile\"] == q].copy()\n",
        "\n",
        "    # Build training design matrix (defines drop_cols for this run)\n",
        "    X_tr, drop_cols = build_X_no_irsd(train_q, drop_cols=None)\n",
        "    train_surv = pd.concat(\n",
        "        [train_q[[\"cvd_time\", \"cvd_event\"]].reset_index(drop=True),\n",
        "         X_tr.reset_index(drop=True)],\n",
        "        axis=1\n",
        "    ).dropna()\n",
        "\n",
        "    # Fit Cox on training data\n",
        "    cph = CoxPHFitter(penalizer=penalizer)\n",
        "    cph.fit(train_surv, duration_col=\"cvd_time\", event_col=\"cvd_event\")\n",
        "\n",
        "    # Build testing design matrix (use training-derived drop_cols)\n",
        "    X_te, _ = build_X_no_irsd(test_q, drop_cols=drop_cols)\n",
        "    test_surv = pd.concat(\n",
        "        [test_q[[\"cvd_time\", \"cvd_event\"]].reset_index(drop=True),\n",
        "         X_te.reset_index(drop=True)],\n",
        "        axis=1\n",
        "    ).dropna()\n",
        "\n",
        "    if test_surv.shape[0] < 200:\n",
        "        loo_rows.append((q, np.nan, np.nan, test_surv.shape[0]))\n",
        "        continue\n",
        "\n",
        "    y_time  = test_surv[\"cvd_time\"].to_numpy(float)\n",
        "    y_event = test_surv[\"cvd_event\"].to_numpy(int)\n",
        "    X_te_final = test_surv.drop(columns=[\"cvd_time\", \"cvd_event\"])\n",
        "\n",
        "    risk_t = predict_risk_at_t(cph, X_te_final, t)\n",
        "    a, d21, _, _ = calibration_d21_by_qbins(risk_t, y_time, y_event, t, K=K)\n",
        "\n",
        "    loo_rows.append((q, a, d21, test_surv.shape[0]))\n",
        "\n",
        "loo_df = pd.DataFrame(loo_rows, columns=[\"IRSD_quintile\", \"a_loo\", \"D21_loo\", \"n_test\"])\n",
        "print(\"\\n=== Leave-one-IRSD-out: train on others (no IRSD feature), test on held-out IRSD ===\")\n",
        "print(loo_df.sort_values(\"IRSD_quintile\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaOd-2EE-9Tu",
        "outputId": "95f18ac8-4eea-418c-9af4-916fa1eb10ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Leave-one-IRSD-out: train on others (no IRSD feature), test on held-out IRSD ===\n",
            "   IRSD_quintile     a_loo   D21_loo  n_test\n",
            "0              1  1.162889  0.162889   10640\n",
            "1              2  1.273879  0.273879    8055\n",
            "2              3  1.238324  0.238324   11941\n",
            "3              4  1.161915  0.161915    8495\n",
            "4              5  1.087939  0.087939   10869\n"
          ]
        }
      ]
    }
  ]
}